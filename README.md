# Human-Activity-Recognition
Multidimensional Sensor Data Analysis Using Deep Learning

## Introduction
Human Activity Recognition (HAR) has emerged as a significant area in the field of machine learning, with profound implications for health monitoring, patient rehabilitation, and lifestyle management. This report delineates our approach to the HAR competition, which is centered around the development of a sophisticated machine-learning model capable of classifying human activities from acceleration data provided by wearable sensors.

![image](https://github.com/user-attachments/assets/d5e13608-62c2-420d-b99e-6da0f0a03547)

The data is time-series in nature, representing human activities through acceleration measurements. It represents the dynamic movement of the human body captured by wearable sensors.

![image](https://github.com/user-attachments/assets/25862973-877d-456b-aa5c-9af1d3e8e1c9)

Example of a record (single trial measurement files):
![image](https://github.com/user-attachments/assets/63515a2d-243a-4b81-a6d7-8334bdca89c1)

To comprehend the data file, examining this image offers insight into the significance of data across the x, y, and z axes. Visualizing the phone in the image as the motion sensor, its movements in different directions align with positional changes along the axes in space, providing an intuitive understanding of the data.

![image](https://github.com/user-attachments/assets/4eb94578-d750-4eb1-9b81-0f19eef54ad6)




